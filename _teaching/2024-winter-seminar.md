---
layout: archive
title: "Seminar: (Auto-)ML for tabular data"
collection: teaching
type: "Seminar"
permalink: /teaching/2024-winter-seminar
venue: "University of TÃ¼bingen"
date: 2024-06-11
location: "TÃ¼bingen"
---

What is tabular data? And which model would you use for it? Why is tabular data challenging for machine learning? And how would you compare learning approaches on tabular data?

**TL;DR** Tabular data is omnipresent and tabular ML offers many solutions.  
This seminar will navigate the landscape of ML models for tabular data (which is the ideal playground for AutoML). We will read recent
research papers in the field of tabular ML with a focus on large- and pretrained neural networks defining model tabular ML.
To get excited, you can have a look at this [position paper on why we need more tabular foundation models](https://arxiv.org/abs/2306.08107).


| Course Title | (Auto-)ML for tabular data                                                                                                                                                                                                          |
|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Course ID    | ML4501f                                                                                                                                                                                                                             |
| Registration | [ILIAS](https://ovidius.uni-tuebingen.de/ilias3/goto.php?target=crs_4780184&client_id=pr02)                                                                                                                                         |
| ECTS         | 3                                                                                                                                                                                                                                   |
| Time         | Thursdays, 14:15-15:45                                                                                                                                                                                                              |                                                                                                                                                                                                                                           |
| Language     | english                                                                                                                                                                                                                             |
| #participants | max 14                                                                                                                                                                                                                              |
| Location     | in-person at [Maria-von-Linden-StraÃŸe 6](https://uni-tuebingen.de/einrichtungen/personalvertretungen-beratung-beauftragte/lageplaene/karte-c-sand-aussenbereiche-innenstadt/maria-von-linden-strasse-6/); seminar room ground floor |

Why should you attend this seminar?
---
Tabular data is everywhere any probably you have heard about it in your first machine learning lecture. 
But what is tabular data? And why is it challenging for machine learning? And what are recent models on this modality?

In this seminar, we will discuss these any many more questions. Additionally, besides learning about this topic and practicing your scientific communication skills, you will also 
  * learn about key contributions in the field of tabular machine learning
  * learn how to assess the experimental setup of empirical comparisons
  * be able to discuss recent research on large and pre-trained models for tabular data
  * gain experience in reading, understanding and presenting research papers 

Requirements
---
We strongly recommend that you know the foundations of machine learning and deep learning, including modern neural architectures and transformer models.
Ideally, you also have some experience in applying ML to get the most out of this seminar.

Topics
---
The seminar focuses on understanding the challenges of learning from tabular representations. We will discuss research 
papers trying to understand what makes tabular data a challenging data modality for some model classes and state-of-the-art
ML methods build to excel on this data modality. 

| Date       | Content                                                                                                                                                                                                |
|------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 17.10.2024 | [Orga](https://keggensperger.github.io/files/2024_winter_AutoMLSeminar_Intro.pdf)) / [How to give a good presentation](https://keggensperger.github.io/files/2024_AutoMLSeminar_GoodPresentations.pdf) |
| 24.10.2024 | no meeting                                                                                                                                                                                             |
| 31.10.2024 | Intro I                                                                                                                                                                                                |
| 07.11.2024 | no meeting                                                                                                                                                                                             |
| 14.11.2024 | Intro II                                                                                                                                                                                               |
| 21.11.2024 | slot 1                                                                                                                                                                                                 |
| 28.11.2024 | slot 2                                                                                                                                                                                                 |
| 05.12.2024 | slot 3                                                                                                                                                                                                 |
| 12.12.2024 | slot 4                                                                                                                                                                                                 |
| 19.12.2024 | slot 5                                                                                                                                                                                                 |
| 26.12.2024 | ðŸŒ² no meeting                                                                                                                                                                                          |
| 02.01.2025 | ðŸŽ† no meeting                                                                                                                                                                                          |
| 09.01.2025 | no meeting                                                                                                                                                                                             |
| 16.01.2025 | slot 6                                                                                                                                                                                                 |
| 23.01.2025 | slot 7                                                                                                                                                                                                 |
| 30.01.2025 | buffer / probably no meeting                                                                                                                                                                           |
| 06.02.2025 | buffer / probably no meeting                                                                                                                                                                           |

1. [FTTransformer] Gorishniy et al. [Revisiting Deep Learning Models for Tabular Data](https://proceedings.neurips.cc/paper/2021/hash/9d86d83f925f2149e9edb0ac3b49229c-Abstract.html) (NeurIPS'22)
2. [Why?] Grinsztajn et al. [Why do tree-based models still outperform deeplearning on typical tabular data?](https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Supplemental-Datasets_and_Benchmarks.pdf) (NeurIPSâ€™22)
3. [GAM X LLM] Bordt et al. [Data Science with LLMs and Interpretable Models](https://arxiv.org/pdf/2402.14474) XAI@AAAI'24, Lou et al. [Accurate intelligible models with pairwise interactions](https://dl.acm.org/doi/abs/10.1145/2487575.2487579) (KDD'13)
4. [TabNet] Arik et al. [TabNet: Attentive Interpretable Tabular Learning ](https://ojs.aaai.org/index.php/AAAI/article/view/16826) (AAAI'21)
5. [TabPFN] Hollmann et al. [TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second](https://openreview.net/forum?id=cp5PvcI6w8_) (ICLR'23)
6. [ForestPFN] Breejen et al. [Why In-Context Learning Transformers are Tabular Data Classifiers](https://arxiv.org/abs/2405.13396) (arxiv'24)
7. [MotherNet] MÃ¼ller et al. [MotherNet: A Foundational Hypernetwork for Tabular Classification](https://openreview.net/forum?id=cp5PvcI6w8_) (arxiv'23)
8. [TabR] Gorishniy et al. [TabR: Tabular Deep Learning Meets Nearest Neighbors](https://openreview.net/forum?id=rhgIgTSSxW) (ICLR'24)
9. [Elephant] Bordt et al. [Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models](https://openreview.net/forum?id=HLoWN6m4fS#discussion) (arxiv'24)
10. [FeatureLLM] Han et al. [Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning](https://openreview.net/forum?id=fRG45xL1WT) (ICML'24)
11. [GReat] Borisov et al. [Language Models are Realistic Tabular Data Generators](https://openreview.net/forum?id=cEygmQNOeI) (ICLR'24)
12. [TabDDM] Kotelnikov et al. [TabDDPM: Modelling Tabular Data with Diffusion Models](https://proceedings.mlr.press/v202/kotelnikov23a.html) (ICML'23)
13. [TabLLM] Hegselmann et al. [TabLLM: Few-shot Classification of Tabular Data with Large Language Models](https://proceedings.mlr.press/v206/hegselmann23a.html) (ICML'23)
14. [Tabula8B] Gardner et al. [Large Scale Transfer Learning for Tabular Data via Language Modeling](https://arxiv.org/pdf/2406.12031) (arxiv'24)

How the seminar will look like?
---

We will meet each week (with a few exceptions). In the first few weeks, we will start with introductory lectures on
ML for tabular data (why is this an exciting data modality and why we need AutoML for this) and how to critically review and present research papers. After that, each week, we will have presentations, followed by discussions.

Other Important information
---

**Registration:** Please register on ILIAS. The signup will kept open and unlimited until the first meeting. The registration opens on **September 30th, 12:00, noon**.
In the first meeting, I will give an introduction to the topic and the papers. Afterward, we'll do will do the final and also binding registration and assignment. So, please come to the first lecture!

**Grading/Presentations:** Grades will be based on your presentation, slides, active participation and a short report. Further details will be discussed in the introductory sessions
.


 

